{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1388000c",
   "metadata": {},
   "source": [
    "# Notecard Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b608e",
   "metadata": {},
   "source": [
    "## ROC curves v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a9374da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated plot: roc_card.png\n",
      "Text for back:\n",
      "\n",
      "    Understanding ROC Curves & AUC\n",
      "    -------------------------------\n",
      "    Definition:\n",
      "    An ROC curve plots TPR vs. FPR at various threshold settings,\n",
      "    showing a classifier's ability to distinguish classes.\n",
      "\n",
      "    Key Points:\n",
      "    - Top-Left Corner: Ideal.\n",
      "    - Diagonal: Random guess.\n",
      "    - AUC: Area Under the Curve.\n",
      "        - AUC=1: Perfect. AUC=0.5: Random. Higher = Better.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "def generate_roc_card(filename=\"roc_card.png\"):\n",
    "    # --- Data for a good classifier ---\n",
    "    y_true_good = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "    y_scores_good = np.array([0.1, 0.2, 0.3, 0.4, 0.6, 0.7, 0.8, 0.9, 0.95, 0.55]) # Scores for class 1\n",
    "\n",
    "    # --- Data for a near-random classifier ---\n",
    "    y_true_random = y_true_good\n",
    "    y_scores_random = np.array([0.4, 0.6, 0.5, 0.3, 0.7, 0.45, 0.55, 0.65, 0.35, 0.51])\n",
    "\n",
    "    fpr_good, tpr_good, _ = roc_curve(y_true_good, y_scores_good)\n",
    "    roc_auc_good = auc(fpr_good, tpr_good)\n",
    "\n",
    "    fpr_random, tpr_random, _ = roc_curve(y_true_random, y_scores_random)\n",
    "    roc_auc_random = auc(fpr_random, tpr_random)\n",
    "\n",
    "    # --- Create the plot ---\n",
    "    # Adjust figsize and dpi for 3x5 output. For a 5-inch wide card:\n",
    "    # 5 inches * 150 dpi = 750 pixels\n",
    "    # 3 inches * 150 dpi = 450 pixels\n",
    "    fig, ax = plt.subplots(figsize=(5, 3), dpi=150) # Inches\n",
    "\n",
    "    ax.plot(fpr_good, tpr_good, color='blue', lw=2,\n",
    "             label=f'Good Classifier (AUC = {roc_auc_good:.2f})')\n",
    "    ax.plot(fpr_random, tpr_random, color='orange', lw=2,\n",
    "             label=f'Near Random (AUC = {roc_auc_random:.2f})')\n",
    "    ax.plot([0, 1], [0, 1], color='gray', lw=1.5, linestyle='--', label='Random Chance (AUC = 0.5)')\n",
    "\n",
    "    ax.set_xlim([-0.05, 1.05])\n",
    "    ax.set_ylim([-0.05, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate (FPR)', fontsize=8)\n",
    "    ax.set_ylabel('True Positive Rate (TPR)', fontsize=8)\n",
    "    ax.set_title('ROC Curve Examples', fontsize=10)\n",
    "    ax.legend(loc=\"lower right\", fontsize=7)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout() # Adjusts plot to prevent labels from being cut off\n",
    "\n",
    "    # --- Save the front of the card ---\n",
    "    plt.savefig(filename)\n",
    "    plt.close(fig) # Close the figure to free up memory\n",
    "\n",
    "    # --- Text for the back of the card (you'd handle printing this separately or combine in a PDF tool) ---\n",
    "    back_text = f\"\"\"\n",
    "    Understanding ROC Curves & AUC\n",
    "    -------------------------------\n",
    "    Definition:\n",
    "    An ROC curve plots TPR vs. FPR at various threshold settings,\n",
    "    showing a classifier's ability to distinguish classes.\n",
    "\n",
    "    Key Points:\n",
    "    - Top-Left Corner: Ideal.\n",
    "    - Diagonal: Random guess.\n",
    "    - AUC: Area Under the Curve.\n",
    "        - AUC=1: Perfect. AUC=0.5: Random. Higher = Better.\n",
    "    \"\"\"\n",
    "    print(f\"Generated plot: {filename}\")\n",
    "    print(f\"Text for back:\\n{back_text}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    generate_roc_card()\n",
    "    # You could extend this to generate cards for:\n",
    "    # - Confusion Matrix (with interpretation)\n",
    "    # - Precision-Recall Curve\n",
    "    # - Overfitting vs. Underfitting (e.g., train/validation loss curves)\n",
    "    # - Effect of a hyperparameter on a simple dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7549fa8c",
   "metadata": {},
   "source": [
    "## ROC curves v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "943c7551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated plot: roc_card_smoother.png\n",
      "Text for back:\n",
      "\n",
      "    Understanding ROC Curves & AUC\n",
      "    -------------------------------\n",
      "    Definition:\n",
      "    An ROC curve plots TPR vs. FPR at various threshold settings,\n",
      "    showing a classifier's ability to distinguish classes.\n",
      "\n",
      "    Key Points:\n",
      "    - Top-Left Corner: Ideal.\n",
      "    - Diagonal: Random guess.\n",
      "    - AUC: Area Under the Curve.\n",
      "        - AUC=1: Perfect. AUC=0.5: Random. Higher = Better.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "def generate_roc_card_smoother(filename=\"roc_card_smoother.png\"):\n",
    "    # --- Generate more data points ---\n",
    "    np.random.seed(42) # for reproducibility\n",
    "    n_samples = 100 # Increased number of samples\n",
    "\n",
    "    # Data for a good classifier\n",
    "    # Class 0 will have lower scores, Class 1 will have higher scores\n",
    "    y_true_good = np.concatenate([np.zeros(n_samples//2), np.ones(n_samples//2)])\n",
    "    # Scores for class 0 (lower values, some overlap)\n",
    "    scores_class0_good = np.random.normal(loc=0.3, scale=0.15, size=n_samples//2)\n",
    "    # Scores for class 1 (higher values, some overlap)\n",
    "    scores_class1_good = np.random.normal(loc=0.7, scale=0.15, size=n_samples//2)\n",
    "    y_scores_good = np.clip(np.concatenate([scores_class0_good, scores_class1_good]), 0, 1) # Clip to [0,1]\n",
    "\n",
    "    # Data for a near-random classifier\n",
    "    # Scores will be more mixed, less separation\n",
    "    y_true_random = y_true_good # Same true labels\n",
    "    scores_class0_random = np.random.normal(loc=0.45, scale=0.2, size=n_samples//2)\n",
    "    scores_class1_random = np.random.normal(loc=0.55, scale=0.2, size=n_samples//2)\n",
    "    y_scores_random = np.clip(np.concatenate([scores_class0_random, scores_class1_random]), 0, 1)\n",
    "\n",
    "    # --- Calculate ROC curve and AUC ---\n",
    "    fpr_good, tpr_good, _ = roc_curve(y_true_good, y_scores_good)\n",
    "    roc_auc_good = auc(fpr_good, tpr_good)\n",
    "\n",
    "    fpr_random, tpr_random, _ = roc_curve(y_true_random, y_scores_random)\n",
    "    roc_auc_random = auc(fpr_random, tpr_random)\n",
    "\n",
    "    # --- Create the plot ---\n",
    "    fig, ax = plt.subplots(figsize=(5, 3), dpi=150) # Inches\n",
    "\n",
    "    ax.plot(fpr_good, tpr_good, color='blue', lw=2,\n",
    "             label=f'Good Classifier (AUC = {roc_auc_good:.2f})')\n",
    "    ax.plot(fpr_random, tpr_random, color='orange', lw=2,\n",
    "             label=f'Near Random (AUC = {roc_auc_random:.2f})')\n",
    "    ax.plot([0, 1], [0, 1], color='gray', lw=1.5, linestyle='--', label='Random Chance (AUC = 0.5)')\n",
    "\n",
    "    ax.set_xlim([-0.05, 1.05])\n",
    "    ax.set_ylim([-0.05, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate (FPR)', fontsize=8)\n",
    "    ax.set_ylabel('True Positive Rate (TPR)', fontsize=8)\n",
    "    ax.set_title('ROC Curve Examples (Smoother)', fontsize=10)\n",
    "    ax.legend(loc=\"lower right\", fontsize=7)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(filename)\n",
    "    plt.close(fig)\n",
    "\n",
    "    back_text = f\"\"\"\n",
    "    Understanding ROC Curves & AUC\n",
    "    -------------------------------\n",
    "    Definition:\n",
    "    An ROC curve plots TPR vs. FPR at various threshold settings,\n",
    "    showing a classifier's ability to distinguish classes.\n",
    "\n",
    "    Key Points:\n",
    "    - Top-Left Corner: Ideal.\n",
    "    - Diagonal: Random guess.\n",
    "    - AUC: Area Under the Curve.\n",
    "        - AUC=1: Perfect. AUC=0.5: Random. Higher = Better.\n",
    "    \"\"\"\n",
    "    print(f\"Generated plot: {filename}\")\n",
    "    print(f\"Text for back:\\n{back_text}\") # This would be for the other side of your notecard\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    generate_roc_card_smoother()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d940a1",
   "metadata": {},
   "source": [
    "More data = Smoother roc curve (100 samples vs 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d1d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1161f1b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
